{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Copy of Original Web App.ipynb","provenance":[{"file_id":"1c2_8e5Vc_f1POxvT26kXrMqUQLgWqoKj","timestamp":1617211989208},{"file_id":"1ZbhS7j9rQxx5RaHy-6lVHOrDOoJeoAOw","timestamp":1613580518782},{"file_id":"1CHLCarTgiZPEKs91dW2M3FE_IC7mACmr","timestamp":1613572161420}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GQNl5_l1ulfV"},"source":["Refer to this blog\n","\n","https://diazoniclabs.medium.com/running-streamlit-from-google-colab-24755e348537"]},{"cell_type":"code","metadata":{"id":"YV2aclmSc7Et","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617199197877,"user_tz":-330,"elapsed":21983,"user":{"displayName":"Tasmiya Shaikh","photoUrl":"","userId":"08219805421211788165"}},"outputId":"b86bdeb4-2ced-44ec-b8c0-0b1805dbac9e"},"source":["!pip install streamlit --quiet\n","!pip install pyngrok==4.1.1 --quiet\n","from pyngrok import ngrok"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 7.0MB 5.4MB/s \n","\u001b[K     |████████████████████████████████| 163kB 45.7MB/s \n","\u001b[K     |████████████████████████████████| 4.6MB 39.7MB/s \n","\u001b[K     |████████████████████████████████| 81kB 7.3MB/s \n","\u001b[K     |████████████████████████████████| 112kB 54.4MB/s \n","\u001b[K     |████████████████████████████████| 71kB 6.9MB/s \n","\u001b[K     |████████████████████████████████| 122kB 46.4MB/s \n","\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.3 which is incompatible.\u001b[0m\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hprq2-AYdDwX","executionInfo":{"status":"ok","timestamp":1617211847920,"user_tz":-330,"elapsed":1201,"user":{"displayName":"Tasmiya Shaikh","photoUrl":"","userId":"08219805421211788165"}},"outputId":"39c2380d-ab8b-4c05-a900-8895b5d404a3"},"source":["%%writefile app.py\n","import streamlit as st\n","import tensorflow as tf\n","import pandas as pd\n","from PIL import Image\n","from tensorflow.keras.models import load_model\n","st.set_option('deprecation.showPyplotGlobalUse', False)\n","st.header('EQUITY MARKET PREDICTION AND ANALYSIS')\n","import pandas_datareader as pdr\n","import numpy as np\n","#image = Image.open('image.png')\n","#st.image(image,use_column_width=True)\n","\n","radio_list=['Service Company','Product Company']\n","select_type=st.sidebar.radio('Select Company Type',radio_list)\n","\n","if select_type=='Service Company':\n","  stock_list = [ 'INFY','WIT','TCS','CTSH','ORCL','GS','TDC','CAP.PA','LTI.NS']\n","  select = st.sidebar.selectbox('Select Company',stock_list)\n","  st.write(select)\n","  if select == 'INFY':\n","        model = load_model('infosys.hdf5')\n","  elif select =='WIT':\n","      model = load_model('wipro.hdf5')\n","  elif select =='TCS':\n","      model = load_model('tcs.hdf5')\n","  elif select =='CTSH':\n","      model = load_model('cognizant.hdf5')\n","  elif select =='ORCL':\n","      model = load_model('oracle.hdf5')\n","  elif select =='GS':\n","      model = load_model('goldmansachs.hdf5')\n","  elif select =='TDC':\n","      model = load_model('teradata.hdf5')\n","  elif select =='CAP.PA':\n","      model = load_model('capgemini.hdf5')\n","  elif select =='LTI.NS':\n","      model = load_model('lti.hdf5')\n","elif select_type=='Product Company':\n","  stock_list = ['AAPL','BABA','GOOGL','MSFT','AMZN', 'ADBE','DELL','HP','SNE']\n","  select = st.sidebar.selectbox('Select IT Product Company',stock_list)\n","  st.write(select)\n","  if select == 'AAPL':\n","        model = load_model('apple.hdf5')\n","  elif select =='BABA':\n","      model = load_model('baba.hdf5')\n","  elif select =='GOOGL':\n","      model = load_model('Google.hdf5')\n","  elif select =='MSFT':\n","      model = load_model('microsoft.hdf5')\n","  elif select =='AMZN':\n","      model = load_model('amazon.hdf5')\n","  elif select =='ADBE':\n","      model = load_model('adobe.hdf5')\n","  elif select =='DELL':\n","      model = load_model('dell.hdf5')\n","  elif select =='HP':\n","      model = load_model('hp.hdf5')\n","  elif select =='SNE':\n","      model = load_model('sony.hdf5')\n","\n","\n","df = pdr.DataReader(select, data_source='yahoo',start='2015-05-27', end='2020-05-22')\n","df1=df.reset_index()['Close']\n","from sklearn.preprocessing import MinMaxScaler\n","scaler=MinMaxScaler(feature_range=(0,1))\n","df1=scaler.fit_transform(np.array(df1).reshape(-1,1))\n","training_size=int(len(df1)*0.65)\n","test_size=len(df1)-training_size\n","train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]\n","\n","import numpy\n","# convert an array of values into a dataset matrix\n","def create_dataset(dataset, time_step=1):\n","\tdataX, dataY = [], []\n","\tfor i in range(len(dataset)-time_step-1):\n","\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n","\t\tdataX.append(a)\n","\t\tdataY.append(dataset[i + time_step, 0])\n","\treturn numpy.array(dataX), numpy.array(dataY)\n"," \n","# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n","time_step = 100\n","X_train, y_train = create_dataset(train_data, time_step)\n","X_test, ytest = create_dataset(test_data, time_step)\n","\n","# reshape input to be [samples, time steps, features] which is required for LSTM\n","X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n","X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n","\n","test_predict=model.predict(X_test)\n","test_predict=scaler.inverse_transform(test_predict)\n","\n","x_input=test_data[len(test_data)-100:].reshape(1,-1)\n","#x_input.shape\n","temp_input=list(x_input)\n","temp_input=temp_input[0].tolist()\n","\n","from numpy import array\n","\n","lst_output=[]\n","n_steps=100\n","i=0\n","\n","days_p = st.sidebar.slider('Days to forecast',1,30)\n","while(i<days_p):\n","    if(len(temp_input)>100):\n","        x_input=np.array(temp_input[1:])\n","        x_input=x_input.reshape(1,-1)\n","        x_input = x_input.reshape((1, n_steps, 1))\n","        yhat = model.predict(x_input, verbose=0)\n","        temp_input.extend(yhat[0].tolist())\n","        temp_input=temp_input[1:]\n","        lst_output.extend(yhat.tolist())\n","        i=i+1\n","    else:\n","        x_input = x_input.reshape((1, n_steps,1))\n","        yhat = model.predict(x_input, verbose=0)\n","        temp_input.extend(yhat[0].tolist())\n","        lst_output.extend(yhat.tolist())\n","        i=i+1\n","day_new=np.arange(1,101)\n","day_pred=np.arange(101,101+days_p)\n","import matplotlib.pyplot as plt\n","#visualize the closeing price history\n","plt.figure(figsize=(16,8))\n","st.subheader(\"Close Price History\")\n","#plt.title(,fontsize=18)\n","plt.plot(df['Close'])\n","plt.xlabel('Date', fontsize=18)\n","plt.ylabel('Close Price USD ($)', fontsize=18)\n","st.pyplot()\n","plt.figure(figsize=(16,8))\n","st.subheader(\"Test Data -100 Days\")\n","plt.plot(day_new,scaler.inverse_transform(df1[len(train_data)+len(test_data)-100:]))\n","plt.xlabel('No of Days', fontsize=18)\n","plt.ylabel(' Price USD ($)', fontsize=18)\n","plt.plot(day_pred,scaler.inverse_transform(lst_output))\n","st.pyplot()\n","plt.figure(figsize=(16,8))\n","st.subheader(\"Test Data - 100 Days (Normalized)\")\n","df3=df1.tolist()\n","df3.extend(lst_output)\n","plt.plot(df3[len(train_data)+len(test_data)-100:])\n","plt.xlabel('No of days',fontsize=18) \n","plt.ylabel('Price',fontsize=18)\n","st.pyplot()\n","df3=scaler.inverse_transform(df3).tolist()\n","# #plot the data\n","data= df.filter(['Close'])\n","train = data[:training_size+101]\n","valid = data[training_size+101:]\n","valid['Predictions']= test_predict\n","#print(valid)\n","#visualize the data\n","plt.figure(figsize=(16,8))\n","st.subheader(\"Model\")\n","plt.xlabel('Date', fontsize=18)\n","plt.ylabel('Close Price USD ($)', fontsize=18)\n","plt.plot(train['Close'])\n","plt.plot(valid[['Close', 'Predictions']])\n","plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n","st.pyplot()\n","st.subheader(\"Prediction and Close comparison\")\n","st.write(valid)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Writing app.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ptMe2c-pVuHZ"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RzneSELhdLmp","executionInfo":{"status":"ok","timestamp":1617199212142,"user_tz":-330,"elapsed":2460,"user":{"displayName":"Tasmiya Shaikh","photoUrl":"","userId":"08219805421211788165"}},"outputId":"175569d7-de3a-4ba0-a721-6aa17b5eff8c"},"source":["!nohup streamlit run app.py &\n","url = ngrok.connect(port = '8501')\n","print(url)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nohup: appending output to 'nohup.out'\n","http://5f92e1656ba5.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Po4B4GErMRl3"},"source":[""],"execution_count":null,"outputs":[]}]}